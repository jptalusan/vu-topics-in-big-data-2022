{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hadoop",
      "provenance": [],
      "authorship_tag": "ABX9TyP6e4S4FhXpS29bl6ea701c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vu-topics-in-big-data-2021/examples/blob/main/example-map-reduce/colab/hadoop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8QD8JufDgBB"
      },
      "source": [
        "#install java first\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jm4sRuLzDufI"
      },
      "source": [
        "#install hadoop. But we clean up first \n",
        "!rm -rf hadoop-3.1.2.tar.gz hadoop-3.1.2 /usr/local/hadoop\n",
        "#download\n",
        "!wget https://archive.apache.org/dist/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz\n",
        "#untar\n",
        "!tar -xzvf hadoop-3.1.2.tar.gz >/dev/null\n",
        "!mv hadoop-3.1.2 /usr/local/hadoop\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLIB9e_KE8za"
      },
      "source": [
        "#get the data file\n",
        "!wget https://datasets.imdbws.com/title.basics.tsv.gz\n",
        "!gunzip title.basics.tsv.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5ZbiM1nEnMA"
      },
      "source": [
        "#check path and java home\n",
        "!echo $JAVA_HOME\n",
        "os.environ[\"PATH\"]+= os.pathsep + \"/usr/local/hadoop/bin\"\n",
        "!echo $PATH"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSzAtzFJFkap"
      },
      "source": [
        "#check hadoop execution\n",
        "!/usr/local/hadoop/bin/hadoop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1bYn6G2GSoG"
      },
      "source": [
        "%%file mapper.py\n",
        "#!/usr/bin/python2.7\n",
        "import sys\n",
        "\n",
        "def map_function(title):\n",
        "    fields = title.strip().split('\\t')         # Split title to fields using the data delimeter\n",
        "    primaryTitle = fields[2]                   # Select the required field\n",
        "    for word in primaryTitle.strip().split():  # Split primary title by words\n",
        "        yield word.strip('!\"*#$').lower(), 1                          # Use a word as a key\n",
        "\n",
        "if __name__ == \"__main__\": \n",
        "  for line in sys.stdin:\n",
        "      # Call map_function for each line in the input\n",
        "      for key, value in map_function(line):\n",
        "          # Emit key-value pairs using '|' as a delimeter  \n",
        "          print(key + \"|\" + str(value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJGBloFcGlNt"
      },
      "source": [
        "%%file reducer.py\n",
        "#!/usr/bin/python2.7\n",
        "import sys\n",
        "\n",
        "prev_word = None\n",
        "value_total = 0\n",
        "\n",
        "if __name__ == \"__main__\": \n",
        "  for line in sys.stdin:          # For ever line in the input from stdin\n",
        "      line = line.strip()         # Remove trailing characters\n",
        "      word, value = line.split(\"|\", 1)\n",
        "      value = int(value)\n",
        "\n",
        "      # Remember that Hadoop sorts mapper output by key, and the reducer takes these keys sorted\n",
        "      if prev_word == word:\n",
        "          value_total += value\n",
        "      else:\n",
        "          if prev_word != None:  # Write result to stdout\n",
        "              print(prev_word + \"|\" + str(value_total))\n",
        "\n",
        "\n",
        "          value_total = value\n",
        "          prev_word = word\n",
        "\n",
        "  if prev_word == word:  # Don't forget the last key/value pair\n",
        "      print(prev_word + \"|\" + str(value_total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBXsBulVLpC6"
      },
      "source": [
        "#give execute permission and clean output dir\n",
        "!chmod +x mapper.py reducer.py\n",
        "!rm -rf outputdir/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-IWBXSrGv81"
      },
      "source": [
        "#run hadoop\n",
        "!hadoop jar /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-3.1.2.jar -input title.basics.tsv -output outputdir -mapper mapper.py -reducer reducer.py -file mapper.py -file reducer.py "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLe3gEm-M5Na"
      },
      "source": [
        "!ls -l outputdir/\n",
        "!mv outputdir/part-00000 outputdir/hadoop-out.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVwc-_fxNS5g"
      },
      "source": [
        "#download file\n",
        "from google.colab import files\n",
        "files.download('outputdir/hadoop-out.txt') "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}